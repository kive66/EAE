2023-02-28 14:31:47,476 - config.py - 111 - INFO - ******HYPER-PARAMETERS******
2023-02-28 14:31:47,477 - config.py - 113 - INFO - exp_purpose: decode
2023-02-28 14:31:47,477 - config.py - 113 - INFO - model: bert
2023-02-28 14:31:47,477 - config.py - 113 - INFO - dataset: rams
2023-02-28 14:31:47,478 - config.py - 113 - INFO - train_path: data/rams/decoder/train.json
2023-02-28 14:31:47,478 - config.py - 113 - INFO - test_path: data/rams/decoder/test.json
2023-02-28 14:31:47,478 - config.py - 113 - INFO - exp_path: ./exp/
2023-02-28 14:31:47,478 - config.py - 113 - INFO - save_path: exp/2023-02-28/rams_bert_20230228143146/best.pth
2023-02-28 14:31:47,478 - config.py - 113 - INFO - project_path: ./
2023-02-28 14:31:47,479 - config.py - 113 - INFO - save_scriptList: ['utils', 'models', 'trainer', 'configs']
2023-02-28 14:31:47,479 - config.py - 113 - INFO - do_train: True
2023-02-28 14:31:47,479 - config.py - 113 - INFO - do_test: False
2023-02-28 14:31:47,479 - config.py - 113 - INFO - require_improvement: 200000000
2023-02-28 14:31:47,479 - config.py - 113 - INFO - num_epochs: 20
2023-02-28 14:31:47,480 - config.py - 113 - INFO - batch_size: 2
2023-02-28 14:31:47,480 - config.py - 113 - INFO - test_batch_size: 1
2023-02-28 14:31:47,480 - config.py - 113 - INFO - max_seq_len: 512
2023-02-28 14:31:47,480 - config.py - 113 - INFO - eval_step: 230
2023-02-28 14:31:47,480 - config.py - 113 - INFO - log_step: 20
2023-02-28 14:31:47,480 - config.py - 113 - INFO - pretrain_path: bert-base-uncased
2023-02-28 14:31:47,481 - config.py - 113 - INFO - hidden_size: 768
2023-02-28 14:31:47,481 - config.py - 113 - INFO - logger: <Logger 20230228143146 (DEBUG)>
2023-02-28 14:31:47,481 - config.py - 113 - INFO - tokenizer: BertTokenizerFast(name_or_path='bert-base-uncased', vocab_size=30522, model_max_length=512, is_fast=True, padding_side='right', truncation_side='right', special_tokens={'unk_token': '[UNK]', 'sep_token': '[SEP]', 'pad_token': '[PAD]', 'cls_token': '[CLS]', 'mask_token': '[MASK]'})
2023-02-28 14:31:47,481 - config.py - 113 - INFO - device: cuda
2023-02-28 14:31:47,482 - config.py - 113 - INFO - basic_learning_rate: 0.0001
2023-02-28 14:31:47,482 - config.py - 113 - INFO - encoder_learning_rate: 3e-05
2023-02-28 14:31:47,482 - config.py - 113 - INFO - rate_warmup_steps: 0.1
2023-02-28 14:31:47,482 - config.py - 113 - INFO - shuffle: True
2023-02-28 14:31:47,482 - config.py - 113 - INFO - drop_last: True
2023-02-28 14:31:47,483 - config.py - 113 - INFO - num_workers: 4
2023-02-28 14:31:47,483 - config.py - 113 - INFO - startTime: 20230228143146
2023-02-28 14:31:47,483 - config.py - 113 - INFO - dev_path: data/rams/decoder/dev.json
2023-02-28 14:31:47,483 - config.py - 113 - INFO - path: exp/2023-02-28/rams_bert_20230228143146
2023-02-28 14:31:47,483 - config.py - 113 - INFO - log_path: exp/2023-02-28/rams_bert_20230228143146/logs.log
2023-02-28 14:31:47,483 - config.py - 113 - INFO - tensorBoard_path: exp/2023-02-28/rams_bert_20230228143146/tensorboard
2023-02-28 14:31:47,484 - config.py - 113 - INFO - script_path: exp/2023-02-28/rams_bert_20230228143146/script
2023-02-28 14:31:47,484 - config.py - 113 - INFO - threshold: 0.4
2023-02-28 14:31:47,484 - config.py - 113 - INFO - max_desc_seq_len: 512
2023-02-28 14:31:47,484 - config.py - 113 - INFO - drop_rate: 0.5
2023-02-28 14:31:47,484 - config.py - 113 - INFO - max_role_num: 5
2023-02-28 14:31:47,485 - config.py - 113 - INFO - event_path: data/rams/event_role_multiplicities.txt
2023-02-28 14:31:47,485 - config.py - 113 - INFO - tbWriter: <torch.utils.tensorboard.writer.SummaryWriter object at 0x7f5002644b20>
2023-02-28 14:31:47,485 - config.py - 114 - INFO - ****************************
2023-02-28 14:31:53,997 - decoder_train.py - 35 - INFO - load train set......
2023-02-28 14:31:54,307 - decoder_train.py - 39 - INFO - load test set......
2023-02-28 14:31:54,598 - basic_trainer.py - 179 - INFO - ******************** Epoch: 1/20 ***********************
2023-02-28 14:31:56,050 - basic_trainer.py - 191 - INFO - step: 0/460, Train loss: 447.72
2023-02-28 14:32:12,536 - basic_trainer.py - 191 - INFO - step: 20/460, Train loss: 1431.33
2023-02-28 14:32:28,746 - basic_trainer.py - 191 - INFO - step: 40/460, Train loss: 833.78
2023-02-28 14:32:44,815 - basic_trainer.py - 191 - INFO - step: 60/460, Train loss: 620.95
2023-02-28 14:33:01,061 - basic_trainer.py - 191 - INFO - step: 80/460, Train loss: 158.44
2023-02-28 14:33:17,037 - basic_trainer.py - 191 - INFO - step: 100/460, Train loss: 39.67
2023-02-28 14:33:32,686 - basic_trainer.py - 191 - INFO - step: 120/460, Train loss: 22.26
2023-02-28 14:33:48,400 - basic_trainer.py - 191 - INFO - step: 140/460, Train loss: 23.34
2023-02-28 14:34:04,367 - basic_trainer.py - 191 - INFO - step: 160/460, Train loss: 21.90
2023-02-28 14:34:19,914 - basic_trainer.py - 191 - INFO - step: 180/460, Train loss: 20.27
2023-02-28 14:34:36,584 - basic_trainer.py - 191 - INFO - step: 200/460, Train loss: 22.29
2023-02-28 14:34:52,631 - basic_trainer.py - 191 - INFO - step: 220/460, Train loss: 20.06
2023-02-28 14:38:09,193 - decoder_trainer.py - 78 - INFO - Test loss: 10.11
2023-02-28 14:38:09,194 - decoder_trainer.py - 79 - INFO - ---------------------------------------------------------------------
2023-02-28 14:38:09,194 - decoder_trainer.py - 80 - INFO - Arg      - P:   0.00            , R:   0.00            , F:   0.00
2023-02-28 14:38:09,194 - decoder_trainer.py - 82 - INFO - ---------------------------------------------------------------------
2023-02-28 14:38:09,204 - basic_trainer.py - 234 - INFO - step: 230/460, test acc: 0.0, Time usage: 0:06:15 [*]
2023-02-28 14:38:17,818 - basic_trainer.py - 191 - INFO - step: 240/460, Train loss: 17.45
2023-02-28 14:38:34,229 - basic_trainer.py - 191 - INFO - step: 260/460, Train loss: 20.50
2023-02-28 14:38:51,751 - basic_trainer.py - 191 - INFO - step: 280/460, Train loss: 21.48
2023-02-28 14:39:08,193 - basic_trainer.py - 191 - INFO - step: 300/460, Train loss: 17.89
2023-02-28 14:39:26,050 - basic_trainer.py - 191 - INFO - step: 320/460, Train loss: 21.01
2023-02-28 14:39:42,259 - basic_trainer.py - 191 - INFO - step: 340/460, Train loss: 17.46
2023-02-28 14:39:57,858 - basic_trainer.py - 191 - INFO - step: 360/460, Train loss: 19.54
2023-02-28 14:40:13,442 - basic_trainer.py - 191 - INFO - step: 380/460, Train loss: 16.78
2023-02-28 14:40:29,398 - basic_trainer.py - 191 - INFO - step: 400/460, Train loss: 16.96
2023-02-28 14:40:45,737 - basic_trainer.py - 191 - INFO - step: 420/460, Train loss: 20.44
2023-02-28 14:41:01,010 - basic_trainer.py - 191 - INFO - step: 440/460, Train loss: 13.86
2023-02-28 14:41:16,836 - basic_trainer.py - 179 - INFO - ******************** Epoch: 2/20 ***********************
2023-02-28 14:41:18,265 - basic_trainer.py - 191 - INFO - step: 0/460, Train loss: 17.25
2023-02-28 14:44:36,481 - decoder_trainer.py - 78 - INFO - Test loss: 9.42
2023-02-28 14:44:36,482 - decoder_trainer.py - 79 - INFO - ---------------------------------------------------------------------
2023-02-28 14:44:36,482 - decoder_trainer.py - 80 - INFO - Arg      - P:  71.05            , R:   0.44            , F:   0.88
2023-02-28 14:44:36,482 - decoder_trainer.py - 82 - INFO - ---------------------------------------------------------------------
2023-02-28 14:44:36,492 - basic_trainer.py - 234 - INFO - step: 0/460, test acc: 0.21626185269381368, Time usage: 0:12:42 [*]
2023-02-28 14:44:54,918 - basic_trainer.py - 191 - INFO - step: 20/460, Train loss: 17.58
2023-02-28 14:45:10,722 - basic_trainer.py - 191 - INFO - step: 40/460, Train loss: 16.37
2023-02-28 14:45:25,974 - basic_trainer.py - 191 - INFO - step: 60/460, Train loss: 13.54
2023-02-28 14:45:42,230 - basic_trainer.py - 191 - INFO - step: 80/460, Train loss: 17.38
2023-02-28 14:45:58,109 - basic_trainer.py - 191 - INFO - step: 100/460, Train loss: 17.30
2023-02-28 14:46:13,543 - basic_trainer.py - 191 - INFO - step: 120/460, Train loss: 13.74
2023-02-28 14:46:29,510 - basic_trainer.py - 191 - INFO - step: 140/460, Train loss: 15.05
2023-02-28 14:46:46,081 - basic_trainer.py - 191 - INFO - step: 160/460, Train loss: 18.93
2023-02-28 14:47:01,911 - basic_trainer.py - 191 - INFO - step: 180/460, Train loss: 15.25
2023-02-28 14:47:19,570 - basic_trainer.py - 191 - INFO - step: 200/460, Train loss: 18.23
2023-02-28 14:47:36,126 - basic_trainer.py - 191 - INFO - step: 220/460, Train loss: 16.51
2023-02-28 14:51:02,590 - decoder_trainer.py - 78 - INFO - Test loss: 8.53
2023-02-28 14:51:02,591 - decoder_trainer.py - 79 - INFO - ---------------------------------------------------------------------
2023-02-28 14:51:02,591 - decoder_trainer.py - 80 - INFO - Arg      - P:  48.84            , R:   3.81            , F:   7.07
2023-02-28 14:51:02,592 - decoder_trainer.py - 82 - INFO - ---------------------------------------------------------------------
2023-02-28 14:51:02,602 - basic_trainer.py - 234 - INFO - step: 230/460, test acc: 0.17319736193826657, Time usage: 0:19:08 
2023-02-28 14:51:11,733 - basic_trainer.py - 191 - INFO - step: 240/460, Train loss: 20.38
2023-02-28 14:51:27,632 - basic_trainer.py - 191 - INFO - step: 260/460, Train loss: 13.88
2023-02-28 14:51:43,691 - basic_trainer.py - 191 - INFO - step: 280/460, Train loss: 13.50
2023-02-28 14:51:59,390 - basic_trainer.py - 191 - INFO - step: 300/460, Train loss: 11.97
2023-02-28 14:52:16,001 - basic_trainer.py - 191 - INFO - step: 320/460, Train loss: 15.31
2023-02-28 14:52:32,830 - basic_trainer.py - 191 - INFO - step: 340/460, Train loss: 20.14
2023-02-28 14:52:49,630 - basic_trainer.py - 191 - INFO - step: 360/460, Train loss: 19.07
2023-02-28 14:53:06,313 - basic_trainer.py - 191 - INFO - step: 380/460, Train loss: 16.38
2023-02-28 14:53:22,723 - basic_trainer.py - 191 - INFO - step: 400/460, Train loss: 17.29
2023-02-28 14:53:39,359 - basic_trainer.py - 191 - INFO - step: 420/460, Train loss: 16.75
2023-02-28 14:53:55,322 - basic_trainer.py - 191 - INFO - step: 440/460, Train loss: 21.28
2023-02-28 14:54:12,206 - basic_trainer.py - 179 - INFO - ******************** Epoch: 3/20 ***********************
2023-02-28 14:54:13,638 - basic_trainer.py - 191 - INFO - step: 0/460, Train loss: 16.17
2023-02-28 14:57:32,155 - decoder_trainer.py - 78 - INFO - Test loss: 9.48
2023-02-28 14:57:32,156 - decoder_trainer.py - 79 - INFO - ---------------------------------------------------------------------
2023-02-28 14:57:32,156 - decoder_trainer.py - 80 - INFO - Arg      - P:  35.91            , R:  13.75            , F:  19.88
2023-02-28 14:57:32,156 - decoder_trainer.py - 82 - INFO - ---------------------------------------------------------------------
2023-02-28 14:57:32,166 - basic_trainer.py - 234 - INFO - step: 0/460, test acc: 0.20394470438812695, Time usage: 0:25:38 
2023-02-28 14:57:48,013 - basic_trainer.py - 191 - INFO - step: 20/460, Train loss: 12.97
2023-02-28 14:58:03,703 - basic_trainer.py - 191 - INFO - step: 40/460, Train loss: 18.51
2023-02-28 14:58:20,034 - basic_trainer.py - 191 - INFO - step: 60/460, Train loss: 16.02
2023-02-28 14:58:36,284 - basic_trainer.py - 191 - INFO - step: 80/460, Train loss: 11.70
